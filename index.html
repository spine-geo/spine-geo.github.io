<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Geometry Meets Vision: Revisiting Pretrained Semantics in Distilled Fields</title>

    <!--  =====  FONTS & ICONS  =====  -->
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" />
    <link rel="icon" href="./static/icon.png" />

    <!--  =====  CSS  =====  -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.4/css/bulma.min.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick-theme.min.css" />

    <style>
        /* --- GLOBAL --- */
        body {
            background: #fff;
            font-family: "Noto Sans", sans-serif;
            font-size: 16px;
            line-height: 1.5;
            color: #333;
        }

        section {
            padding: 2.5rem 0;
        }

        /* --- SECTION COLORS --- */
        .section-gray {
            background: #f7f7f7;
        }

        /* --- TYPOGRAPHY & LINKS --- */
        .task-title {
            margin-bottom: 1rem;
            font-weight: 600;
        }

        .publication-authors {
            margin-bottom: 1rem;
        }

        /* space below authors */
        .publication-authors a {
            color: #3273dc;
            text-decoration: none;
            white-space: nowrap;
        }

        .publication-authors a:hover {
            text-decoration: underline;
        }

        /* --- HERO & SPACING TWEAKS --- */
        .publication-title {
            margin-top: 0.0rem;
            padding-top: 0.0rem;
        }

        .hero {
            padding-top: 0.75rem;
            padding-bottom: 0.5rem;
        }

        /* tighter gap above overview */
        .hero-body {
            padding: 1.5rem;
        }

        #overview.section {
            padding-top: 0.75rem;
        }

        /* tighter gap below hero */
        .publication-links {
            margin-top: 1.5rem;
            margin-bottom: 1.5rem;
        }

        /* gap between authors/icons & icons/logo */
        figure.lab-logo {
            margin-top: 0.75rem;
        }

        /* gap between icons and Princeton logo */
        /* #sim-robot.section{padding-bottom:0.1rem;} gap above simulation section */
        #bibtex.section- {
            padding-top: 0rem;
        }

        /* gap above BibTeX section */

        /* --- SLICK ARROWS --- */
        .slick-prev:before,
        .slick-next:before {
            color: #3273dc;
            font-size: 32px;
        }

        /* --- THUMBNAILS --- */
        .video-thumb {
            cursor: pointer;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            margin: 0 8px;
        }

        .video-thumb video {
            width: 100%;
            height: auto;
            display: block;
        }

        /* --- STAND‑ALONE VIDEOS --- */
        .overview-video,
        .sim-video {
            width: 100%;
            height: auto;
            border-radius: 0;
            box-shadow: none;
            pointer-events: none;
        }

        /* --- LAYOUT HELPERS --- */
        .task-block {
            margin-bottom: 3rem;
        }

        .task-carousel,
        .task-carousel-exp {
            margin-top: 1rem;
        }

        /* --- CONTENT WIDTH CONSISTENCY --- */
        .content-container {
            max-width: 960px;
            margin: 0 auto;
        }

        /* --- PDF EMBED --- */
        .pdf-container {
            margin-top: 1.5rem;
        }

        .pdf-container object {
            width: 100%;
            height: 600px;
            border: none;
        }

        /* --- REAL EXP IMG --- */
        .real-exp-img {
            width: 100%;
            height: auto;
            max-width: 100%;
        }

        /* --- LINK COLOR (lighter blue, closer to default hyperlinks) --- */

        .publication-authors a:hover {
            text-decoration: underline;
        }

        /* --- HERO ↔ OVERVIEW GAP (shrink) --- */
        .hero {
            padding-bottom: 0rem;
        }

        /* was 0.5rem */
        #overview.section {
            padding-top: 0rem;
            padding-bottom: 0rem;
        }

        /* was 0.75rem */

        /* --- REAL-ROBOT ↔ SIMULATION GAP (shrink) --- */
        #real-robot.section {
            padding-top: 2.5rem;
        }

        /* default Bulma ≈2.5rem */
        #real-robot.section {
            padding-bottom: 2.5rem;
        }

        #sim-to-real-1 {
            margin-bottom: 0;
        }

        /* default Bulma ≈2.5rem */
        #sim-robot.section {
            padding-top: 2.5rem;
        }

        /* default Bulma ≈2.5rem */

        /* --- SIMULATION ↔ BIBTEX GAP (shrink) --- */
        #BibTeX.section {
            padding-top: 0.1rem;
        }

        /* tighten above BibTeX */
    </style>
</head>

<body>

    <!-- ===== HERO with title & authors ===== -->
    <section class="hero section">
        <div class="hero-body">
            <div class="container is-max-widescreen has-text-centered">
                <h1 class="title is-2 publication-title">Geometry Meets Vision: <br /> Revisiting Pretrained Semantics
                    in Distilled Fields
                </h1>

                <!-- ===== AUTHORS (three rows, no underscores) ===== -->

                <div class="is-size-5 publication-authors">
                    <div>
                        <span class="author-block"><a
                                href="https://tenny-yinyijun.github.io/">Tenny&nbsp;Yin*</a></span>,
                        <span class="author-block"><a href="https://may0mei.github.io/">Zhiting&nbsp;Mei</a></span>,
                        <span class="author-block"><a href="#">Tao&nbsp;Sun</a></span>,
                    </div>
                    <div>
                        <span class="author-block"><a
                                href="https://www.linkedin.com/in/jeremy-bao/">Jeremy&nbsp;Bao<sup>+</sup></a></span>,
                        <span class="author-block"><a
                                href="https://www.linkedin.com/in/miyu-yamane/">Miyu&nbsp;Yamane<sup>+</sup></a></span>,
                        <span class="author-block"><a href="#">Ola&nbsp;Shorinwa*</a></span>,
                        <span class="author-block"><a
                                href="https://irom-lab.princeton.edu/majumdar/">Anirudha&nbsp;Majumdar</a></span>
                    </div>
                </div>

                <div>
                    <sup>&#42;</sup>Equal Contribution.
                    <sup>+</sup>Authors contributed equally.
                </div>

                <!-- ===== RESOURCE ICONS ===== -->
                <div class="publication-links">
                    <a href="static/paper.pdf" class="external-link button is-normal is-rounded is-dark" target="_blank"
                        rel="noopener">
                        <span class="icon"><i class="fas fa-file-pdf"></i></span><span>Paper</span>
                    </a>
                    <a href="https://arxiv.org/abs/" class="external-link button is-normal is-rounded is-dark"
                        target="_blank" rel="noopener">
                        <span class="icon"><i class="ai ai-arxiv"></i></span><span>arXiv</span>
                    </a>
                    <a href="https://www.youtube.com/" class="external-link button is-normal is-rounded is-dark"
                        target="_blank" rel="noopener">
                        <span class="icon"><i class="fab fa-youtube"></i></span><span>Video</span>
                    </a>
                    <a href="#" class="external-link button is-normal is-rounded is-dark" target="_blank"
                        rel="noopener">
                        <span class="icon"><i class="fab fa-github"></i></span><span>Code (Coming Soon!)</span>
                    </a>
                </div>

                <!-- ===== LAB LOGO ===== -->

                <figure class="image is-inline-block lab-logo">
                    <img src="static/irom_princeton.png" alt="IROM Lab logo" style="max-width:500px;">
                </figure>

            </div>
        </div>
    </section>

    <!-- ===== OVERVIEW ===== -->
    <section id="overview" class="section">
        <div class="container is-max-desktop content-container has-text-centered">
            <video class="overview-video" autoplay loop muted playsinline poster="static/thumbnails/banner.jpg">
                <source src="static/videos/overviews/banner.mp4" type="video/mp4" />
                Your browser does not support the video tag.
            </video>
            <p style="margin-top:1rem;">
                We explore the relative performance of visual-geometry semantics in radiance fields, asking:
                <em>Do geometry-grounded semantic features offer an edge in distilled fields?</em>
                and introduce <strong>SPINE</strong>, a semantics-based method for inverting radiance fields
                without an initial guess.
            </p>
        </div>
    </section>

    <!-- ===== ABSTRACT ===== -->
    <section id="abstract" class="section">
        <div class="container is-max-desktop content-container">
            <h2 class="title is-3 has-text-centered">Abstract</h2>
            <p>
                Semantic distillation in radiance fields has spurred significant advances in open-vocabulary robot
                policies, e.g., in manipulation and navigation, founded on pretrained semantics from large vision
                models.
                While prior work has demonstrated the effectiveness of visual-only semantic features (e.g., DINO and
                CLIP) in Gaussian Splatting and neural radiance fields, the potential benefit of geometry-grounding in
                distilled fields remains an open question. In principle, visual-geometry features seem very promising
                for spatial tasks such as pose estimation, prompting the question: <em>Do geometry-grounded semantic
                    features offer an edge in distilled fields?</em> Specifically, we ask three critical questions:
                First, <em>does spatial-
                    grounding produce higher-fidelity geometry-aware semantic features?</em> We find that image features
                from
                geometry-grounded backbones contain finer structural details compared to their counterparts. Secondly,
                <em>does geometry-grounding improve semantic object localization?</em> We observe no significant
                difference in
                this task. Thirdly, <em>does geometry-grounding enable higher-accuracy radiance field inversion?</em>
                Given
                the limitations of prior work and their lack of semantics integration, we propose a novel framework
                <strong>SPINE</strong> for inverting radiance fields without an initial guess, consisting of two core
                components: (i)
                coarse inversion using distilled semantics, and (ii) fine inversion using photometric-based
                optimization.
                Surprisingly, we find that the pose estimation accuracy decreases with geometry-grounded features.
                Our results suggest that visual-only features offer greater versatility for a broader range of
                downstream
                tasks, although geometry-grounded features contain more geometric detail. Notably, our findings
                underscore the necessity of future research on effective strategies for geometry-grounding that augment
                the versatility and performance of pretrained semantic features.
            </p>
            <!-- <br>
      <video id="summary-video" class="shadow" controls preload="metadata" width="100%" poster="static/thumbnails/talk_video.jpg">
        <source src="static/videos/talk_video.mp4" type="video/mp4" />
        Your browser does not support the video tag.
      </video> -->
        </div>
    </section>

    <!-- ===== Feature Distillation ===== -->
    <section id="feature-distillation" class="section">
        <div class="container is-max-desktop content-container">
            <h2 class="title is-3 has-text-centered">Does spatial-
                grounding produce higher-fidelity geometry-aware semantic features?</h2>
            <video class="overview-video" autoplay loop muted playsinline poster="static/thumbnails/.jpg">
                <source src="static/videos/overviews/.mp4" type="video/mp4" />
                Your browser does not support the video tag.
            </video>
            <br>
            <p>
            </p>
        </div>
    </section>

    <!-- ===== Semantic Content ===== -->
    <section id="semantic-content" class="section">
        <div class="container is-max-desktop content-container">
            <h2 class="title is-3 has-text-centered">Does spatial-
                grounding produce higher-fidelity geometry-aware semantic features?</h2>
            <video class="overview-video" autoplay loop muted playsinline poster="static/thumbnails/.jpg">
                <source src="static/videos/overviews/.mp4" type="video/mp4" />
                Your browser does not support the video tag.
            </video>
            <br>
            <p>
            </p>
        </div>
    </section>

    <!-- ===== Semantic Localization ===== -->
    <section id="semantic-localization" class="section">
        <div class="container is-max-desktop content-container">
            <h2 class="title is-3 has-text-centered">Does geometry-grounding improve semantic object localization?</h2>
            <video class="overview-video" autoplay loop muted playsinline poster="static/thumbnails/.jpg">
                <source src="static/videos/overviews/.mp4" type="video/mp4" />
                Your browser does not support the video tag.
            </video>
            <br>
            <p>
            </p>
        </div>
    </section>

    <!-- ===== RF inversion ===== -->
    <section id="rf-inversion" class="section">
        <div class="container is-max-desktop content-container">
            <h2 class="title is-3 has-text-centered">Does geometry-grounding enable higher-accuracy radiance field
                inversion?</h2>
            <video class="overview-video" autoplay loop muted playsinline poster="static/thumbnails/architecture.jpg">
                <source src="static/videos/overviews/architecture.mp4" type="video/mp4" />
                Your browser does not support the video tag.
            </video>
            <br>
            <p>

            </p>
        </div>
    </section>

    <!-- ===== EXPERIMENT RESULTS ===== -->
    <section id="experiment-results" class="section">
        <div class="container is-max-desktop content-container">
            <h2 class="title is-3 has-text-centered">Experiments</h2>
            <p class="has-text-justified">

            </p>
            <br>

            <!-- ===== Evaluations ===== -->
            <div class="task-block" id="pybullet-1">
                <h3 class="title is-4 task-title">Experiments</h3>
                <div class="task-carousel">
                    <!-- Six videos with poster extracted via Python script -->
                    <div class="video-thumb"><video class="thumb-video" autoplay loop muted playsinline
                            poster="static/thumbnails/experiments/x.jpg" preload="metadata">
                            <source src="static/videos/experiments/x.mp4" type="video/mp4" />
                        </video></div>
                </div>
                <br>

                <!-- Performance plot -->
                <img src="./static/images/x.png" class="real-exp-img" alt=" Evaluation." />
                <p class="has-text-justified">

                </p>
            </div>


            <!-- Performance plot -->
            <img src="./static/images/x.png" class="real-exp-img" alt=" Evaluation." />
        </div>

        </div>
    </section>



    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>@misc{na,
}
        </code></pre>
        </div>
    </section>


    <br>
    <center class="is-size-10">
        The website design was adapted from <a href="https://nerfies.github.io" class="external-link"><span
                class="dnerf">Nerfies</span></a>.
    </center>
    <br>

    <!-- ===== SCRIPTS ===== -->
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.js"></script>
    <script>
        $(function () {
            // Init carousels (only those still using .task-carousel wrappers)
            $('.task-carousel').slick({
                slidesToShow: 4,
                slidesToScroll: 1,
                infinite: false,
                arrows: true,
                dots: false,
                lazyLoad: 'ondemand',
                touchMove: true,
                responsive: [
                    { breakpoint: 1024, settings: { slidesToShow: 3 } },
                    { breakpoint: 768, settings: { slidesToShow: 2 } },
                    { breakpoint: 480, settings: { slidesToShow: 1 } }
                ]
            });

            // Horizontal track‑pad scroll → carousel navigation; let vertical scroll bubble up
            $('.task-carousel').on('wheel', function (e) {
                const deltaX = e.originalEvent.deltaX;
                const deltaY = e.originalEvent.deltaY;
                if (Math.abs(deltaX) > Math.abs(deltaY)) {
                    e.preventDefault();
                    $(this).slick(deltaX < 0 ? 'slickPrev' : 'slickNext');
                }
            });

            $('.task-carousel-exp').slick({
                slidesToShow: 3,
                slidesToScroll: 1,
                infinite: false,
                arrows: true,
                dots: false,
                lazyLoad: 'ondemand',
                touchMove: true,
                responsive: [
                    { breakpoint: 1024, settings: { slidesToShow: 1 } },
                    { breakpoint: 768, settings: { slidesToShow: 1 } },
                    { breakpoint: 480, settings: { slidesToShow: 1 } }
                ]
            });

            // Horizontal track‑pad scroll → carousel navigation; let vertical scroll bubble up
            $('.task-carousel').on('wheel', function (e) {
                const deltaX = e.originalEvent.deltaX;
                const deltaY = e.originalEvent.deltaY;
                if (Math.abs(deltaX) > Math.abs(deltaY)) {
                    e.preventDefault();
                    $(this).slick(deltaX < 0 ? 'slickPrev' : 'slickNext');
                }
            });
            $('.task-carousel-exp').on('wheel', function (e) {
                const deltaX = e.originalEvent.deltaX;
                const deltaY = e.originalEvent.deltaY;
                if (Math.abs(deltaX) > Math.abs(deltaY)) {
                    e.preventDefault();
                    $(this).slick(deltaX < 0 ? 'slickPrev' : 'slickNext');
                }
            });

        });
    </script>
</body>

</html>